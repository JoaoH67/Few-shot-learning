[<StreamHandler <stdout> (NOTSET)>]
==> Epoch 1
> Training
NumExpr defaulting to 8 threads.
Loss: 7.1478
> Validation
Loss: 25.9928
=> This is the best model so far! Saving...
Loss: 5.2924
> Validation
Loss: 24.7158
=> This is the best model so far! Saving...
Loss: 5.1511
> Validation
Loss: 24.1161
=> This is the best model so far! Saving...
Loss: 4.7927
> Validation
Loss: 23.3324
=> This is the best model so far! Saving...
Loss: 4.6680
> Validation
Loss: 23.8249
Loss: 4.4366
> Validation
Loss: 22.0510
=> This is the best model so far! Saving...
Loss: 4.6130
> Validation
Loss: 23.1271
Loss: 4.4323
> Validation
Loss: 22.6203
Loss: 4.2245
> Validation
Loss: 22.1145
Loss: 4.3044
> Validation
Loss: 23.1866
==> Epoch 11
> Training
Loss: 4.2870
> Validation
Loss: 23.6243
Loss: 3.9361
> Validation
Loss: 21.9588
=> This is the best model so far! Saving...
Loss: 4.2241
> Validation
Loss: 22.3854
Loss: 4.1497
> Validation
Loss: 22.3687
Loss: 3.9444
> Validation
Loss: 22.3706
Loss: 3.8882
> Validation
Loss: 22.8286
Loss: 4.0882
> Validation
Loss: 21.9549
=> This is the best model so far! Saving...
Loss: 3.7411
> Validation
Loss: 22.0771
Loss: 3.8681
> Validation
Loss: 22.5539
Loss: 3.9675
> Validation
Loss: 22.8530
==> Epoch 21
> Training
Loss: 3.5647
> Validation
Loss: 22.1714
Loss: 3.7441
> Validation
Loss: 22.5506
Loss: 3.5722
> Validation
Loss: 21.6205
=> This is the best model so far! Saving...
Loss: 3.7599
> Validation
Loss: 22.4528
Loss: 3.6864
> Validation
Loss: 21.5106
=> This is the best model so far! Saving...
Loss: 3.5127
> Validation
Loss: 22.5193
Loss: 3.6742
> Validation
Loss: 22.8148
Loss: 3.3905
> Validation
Loss: 22.7312
Loss: 3.5392
> Validation
Loss: 22.4360
Loss: 3.5040
> Validation
Loss: 22.3839
Best loss: 21.5106
