[<StreamHandler <stdout> (NOTSET)>]
==> Epoch 1
> Training
Loss: 7.0545
> Validation
Loss: 26.1418
=> This is the best model so far! Saving...
Loss: 5.5378
> Validation
Loss: 26.4098
Loss: 4.9936
> Validation
Loss: 25.7374
=> This is the best model so far! Saving...
Loss: 4.9467
> Validation
Loss: 24.6655
=> This is the best model so far! Saving...
Loss: 4.7104
> Validation
Loss: 24.1846
=> This is the best model so far! Saving...
Loss: 4.7984
> Validation
Loss: 23.9665
=> This is the best model so far! Saving...
Loss: 4.5642
> Validation
Loss: 24.2433
Loss: 4.3120
> Validation
Loss: 23.9268
=> This is the best model so far! Saving...
Loss: 4.2975
> Validation
Loss: 24.0729
Loss: 4.1537
> Validation
Loss: 24.2481
==> Epoch 11
> Training
Loss: 4.0662
> Validation
Loss: 23.1132
=> This is the best model so far! Saving...
Loss: 4.0465
> Validation
Loss: 23.1371
Loss: 4.2166
> Validation
Loss: 22.8535
=> This is the best model so far! Saving...
Loss: 4.0794
> Validation
Loss: 22.8585
Loss: 3.8415
> Validation
Loss: 23.0517
Loss: 3.9872
> Validation
Loss: 23.1975
Loss: 4.0636
> Validation
Loss: 23.1373
Loss: 4.1830
> Validation
Loss: 22.4817
=> This is the best model so far! Saving...
Loss: 3.8186
> Validation
Loss: 24.3036
Loss: 4.1162
> Validation
Loss: 23.8542
==> Epoch 21
> Training
Loss: 3.9529
> Validation
Loss: 24.1604
Loss: 3.6955
> Validation
Loss: 23.3890
Loss: 3.9759
> Validation
Loss: 22.8551
Loss: 3.6948
> Validation
Loss: 23.4785
Loss: 3.6334
> Validation
Loss: 22.6817
Loss: 3.6597
> Validation
Loss: 22.7666
Loss: 3.6051
> Validation
Loss: 22.7735
Loss: 3.6944
> Validation
Loss: 22.6552
Loss: 3.6477
> Validation
Loss: 22.9329
Loss: 3.8487
> Validation
Loss: 23.5547
==> Epoch 31
> Training
Loss: 3.7604
> Validation
Loss: 22.7155
Loss: 3.6140
> Validation
Loss: 23.0579
Loss: 3.4083
> Validation
Loss: 23.1725
Loss: 3.4984
> Validation
Loss: 23.8012
Loss: 3.6922
> Validation
Loss: 23.4491
Loss: 3.6608
> Validation
Loss: 22.6210
Loss: 3.8254
> Validation
Loss: 23.3792
Loss: 3.6428
> Validation
Loss: 23.3930
Loss: 3.4610
> Validation
Loss: 23.5731
Loss: 3.5482
> Validation
Loss: 23.9139
==> Epoch 41
> Training
Loss: 3.5409
> Validation
Loss: 22.6244
Loss: 3.5957
> Validation
Loss: 22.9286
Loss: 3.5584
> Validation
Loss: 23.6770
Loss: 3.6035
> Validation
Loss: 23.5046
Loss: 3.4594
> Validation
Loss: 22.1398
=> This is the best model so far! Saving...
Loss: 3.5086
> Validation
Loss: 23.0486
Loss: 3.4374
> Validation
Loss: 23.4941
Loss: 3.5031
> Validation
Loss: 22.3197
Loss: 3.4742
> Validation
Loss: 23.2814
Loss: 3.5435
> Validation
Loss: 22.5736
==> Epoch 51
> Training
Loss: 3.5065
> Validation
Loss: 23.5357
Loss: 3.6269
> Validation
Loss: 22.7815
Loss: 3.5006
> Validation
Loss: 23.0235
Loss: 3.4276
> Validation
Loss: 23.6311
Loss: 3.3956
> Validation
Loss: 23.1051
Loss: 3.3317
> Validation
Loss: 23.6438
Loss: 3.3506
> Validation
Loss: 22.4103
Loss: 3.4034
> Validation
Loss: 23.5980
Loss: 3.3913
> Validation
Loss: 24.0968
Loss: 3.5667
> Validation
Loss: 23.4425
==> Epoch 61
> Training
Loss: 3.3931
> Validation
Loss: 22.3026
Loss: 3.3892
> Validation
Loss: 23.5844
Loss: 3.4954
> Validation
Loss: 23.0610
Loss: 3.3739
> Validation
Loss: 23.0205
Loss: 3.4566
> Validation
Loss: 23.8416
Loss: 3.3701
> Validation
Loss: 23.5188
Loss: 3.3935
> Validation
Loss: 23.7213
Loss: 3.3906
> Validation
Loss: 23.4589
Loss: 3.4732
> Validation
Loss: 22.6769
Loss: 3.4411
> Validation
Loss: 22.2024
==> Epoch 71
> Training
Loss: 3.4351
> Validation
Loss: 22.4362
Loss: 3.5674
> Validation
Loss: 23.5727
Loss: 3.3940
> Validation
Loss: 23.6776
Loss: 3.5818
> Validation
Loss: 23.8391
Loss: 3.3538
> Validation
Loss: 23.3947
Loss: 3.2566
> Validation
Loss: 23.1918
Loss: 3.4399
> Validation
Loss: 23.2025
Loss: 3.2214
> Validation
Loss: 23.1866
Loss: 3.2119
> Validation
Loss: 23.6035
Loss: 3.5890
> Validation
Loss: 23.3525
==> Epoch 81
> Training
Loss: 3.2076
> Validation
Loss: 23.9586
Loss: 3.4449
> Validation
Loss: 23.4382
Loss: 3.3987
> Validation
Loss: 23.5937
Loss: 3.3492
> Validation
Loss: 23.8682
Loss: 3.4145
> Validation
Loss: 23.5692
Loss: 3.4691
> Validation
Loss: 23.3160
Loss: 3.6752
> Validation
Loss: 22.6383
Loss: 3.3594
> Validation
Loss: 22.9497
Loss: 3.4316
> Validation
Loss: 23.1294
Loss: 3.2882
> Validation
Loss: 23.6414
==> Epoch 91
> Training
Loss: 3.5838
> Validation
Loss: 23.3126
Loss: 3.4171
> Validation
Loss: 22.5765
Loss: 3.3144
> Validation
Loss: 23.2510
Loss: 3.4119
> Validation
Loss: 23.2606
Loss: 3.2646
> Validation
Loss: 23.8142
Loss: 3.3293
> Validation
Loss: 23.6643
Loss: 3.3505
> Validation
Loss: 22.3913
Loss: 3.4032
> Validation
Loss: 23.6676
Loss: 3.2556
> Validation
Loss: 23.5353
Loss: 3.2989
> Validation
Loss: 22.9710
Best loss: 22.1398
